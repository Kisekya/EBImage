Running times on lobster for 200 and 300 images - full script
200 images: 1420 s
300 images: 2080 s
NO FAILURES if run with modify=TRUE


Simple test on 3 images
> dim(im)
[1] 696 520   3
> length(im)
[1] 1085760

TEST 1
=======================================================================
Initial state:
library(EBImage)
files = c("01.TIF","02.TIF","03.TIF")
im = read.image(files)

COPY (new object is created, data of the array modified in R):

Memory R occupies in total: 35.7 Mb -> 64.3 Mb over 67.3 Mb
> system.time(im <- normalize(im, independent=TRUE))
[1] 1.58 0.31 1.96 0.00 0.00

--------------------------------------------------------------------
SUBSTITUTE (no new object created, data modified directly in C):

Memory R occupies in total: 35.7 Mb -> 35.7 Mb
> system.time(normalize(im, modify = TRUE, independent = TRUE))
[1] 0.06 0.00 0.05 0.00 0.00
alternatively
> system.time(im<-normalize(im, modify = TRUE, independent = TRUE))
[1] 0.05 0.00 0.05 0.00 0.00

This time difference is another problem, probably it is the same as we discussed
before! The former function (initially, now changed) uses a single R command line to
calculate the normalization (ala res@.Data = (res@.Data - min)*range/(max - min)+range[[1]] ),
the latter is pure C code with two loops in it. The data structure was an array - why there is
such a difference in time?

TEST 2
=======================================================================
Initial state:
library(EBImage)
files = c("01.TIF","02.TIF","03.TIF")
im = read.image(files)
normalize(im, modify = TRUE, independent = TRUE)

COPY

Memory R occupies in total: 35.7 -> 75.5 -> 72.6
> system.time(seg <- tresh(im, 30, 30, 400, TRUE))
[1] 15.04  0.25 15.94  0.00  0.00
--------------------------------------------------------------------

SUBSTITUTE
Memory R occupies in total: 35.7 -> 41.6 -> 35.7
> system.time(tresh(im, 30, 30, 400, TRUE, modify=TRUE))
[1] 14.06  0.11 14.57  0.00  0.00

